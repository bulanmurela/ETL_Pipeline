{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests bs4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4lX35d-mQz5j"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4JoZJnZkEgl"
   },
   "source": [
    "# **EXTRACT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FoaBHuBjRAl5"
   },
   "outputs": [],
   "source": [
    "class BooksDataExtractor:\n",
    "    \"\"\"Combined extractor for NYTimes bestsellers and Goodreads ratings\"\"\"\n",
    "\n",
    "    def __init__(self, nyt_api_key: str):\n",
    "        self.nyt_api_key = nyt_api_key\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        # List kategori buku yang akan diambil\n",
    "        self.categories = [\n",
    "            'childrens-middle-grade-hardcover',\n",
    "            'picture-books',\n",
    "            'series-books',\n",
    "            'young-adult-hardcover'\n",
    "        ]\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger('ETL_Logger')\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "\n",
    "    def _extract_nyt_books(self, list_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Extract current NYT bestseller list for a specific category\"\"\"\n",
    "        self.logger.info(f\"Starting NYTimes extraction for {list_name} list\")\n",
    "\n",
    "        base_url = \"https://api.nytimes.com/svc/books/v3/lists/current\"\n",
    "        endpoint = f\"{base_url}/{list_name}.json\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(endpoint, params={'api-key': self.nyt_api_key})\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            books = []\n",
    "            for book in data['results']['books']:\n",
    "                books.append({\n",
    "                    'title': book['title'],\n",
    "                    'author': book.get('author',''),\n",
    "                    'isbn13': book.get('primary_isbn13'),\n",
    "                    'publisher': book.get('publisher', ''),\n",
    "                    'description': book.get('description', ''),\n",
    "                    'amazon_product_url': book.get('amazon_product_url', ''),\n",
    "                    'nyt_rank': book.get('rank', 0),\n",
    "                    'nyt_rank_last_week': book.get('rank_last_week', 0),\n",
    "                    'weeks_on_list': book.get('weeks_on_list', 0),\n",
    "                    'price': book.get('price', 0),\n",
    "                    'primary_isbn10': book.get('primary_isbn10', ''),\n",
    "                    'category': list_name,  # Menambahkan informasi kategori\n",
    "                    'extraction_date': datetime.now().strftime('%Y-%m-%d')\n",
    "                })\n",
    "\n",
    "            nyt_df = pd.DataFrame(books)\n",
    "            self.logger.info(f\"Successfully extracted {len(books)} books from NYTimes category: {list_name}\")\n",
    "            return nyt_df\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting NYT data for {list_name}: {e}\")\n",
    "            return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "    def _find_goodreads_url(self, isbn: str) -> Optional[str]:\n",
    "        \"\"\"Generate Goodreads book URL using ISBN\"\"\"\n",
    "        if not isbn:\n",
    "            return None\n",
    "        return f\"https://www.goodreads.com/book/isbn/{isbn}\"\n",
    "\n",
    "    def _extract_goodreads_rating(self, soup: BeautifulSoup) -> Tuple[Optional[float], Optional[int]]:\n",
    "        \"\"\"Extract rating and rating count from Goodreads page\"\"\"\n",
    "        try:\n",
    "            # Rating\n",
    "            rating_div = soup.find('div', {'class': 'RatingStatistics__rating'})\n",
    "            rating = float(rating_div.text.strip()) if rating_div else None\n",
    "\n",
    "            # Rating Count\n",
    "            count_div = soup.find('span', {'data-testid': 'ratingsCount'})\n",
    "            if count_div:\n",
    "                count_text = count_div.text.strip().replace(',', '').split()[0]\n",
    "                rating_count = int(count_text)\n",
    "            else:\n",
    "                rating_count = None\n",
    "\n",
    "            return rating, rating_count\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting Goodreads rating: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def _extract_goodreads_data(self, isbn: str) -> Dict:\n",
    "        \"\"\"Extract Goodreads data for a single book\"\"\"\n",
    "        try:\n",
    "            goodreads_url = self._find_goodreads_url(isbn)\n",
    "            if not goodreads_url:\n",
    "                return {\n",
    "                    'goodreads_rating': None,\n",
    "                    'goodreads_rating_count': None,\n",
    "                    'goodreads_url': None\n",
    "                }\n",
    "\n",
    "            # Add randomized delay to avoid rate limiting\n",
    "            time.sleep(random.uniform(1, 2))\n",
    "\n",
    "            # Request Goodreads page\n",
    "            response = requests.get(goodreads_url, headers=self.headers)\n",
    "\n",
    "            # Handle redirects\n",
    "            if len(response.history) > 0:\n",
    "                final_url = response.url\n",
    "                response = requests.get(final_url, headers=self.headers)\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            rating, rating_count = self._extract_goodreads_rating(soup)\n",
    "\n",
    "            return {\n",
    "                'goodreads_rating': rating,\n",
    "                'goodreads_rating_count': rating_count,\n",
    "                'goodreads_url': goodreads_url\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting Goodreads data for ISBN {isbn}: {e}\")\n",
    "            return {\n",
    "                'goodreads_rating': None,\n",
    "                'goodreads_rating_count': None,\n",
    "                'goodreads_url': None\n",
    "            }\n",
    "\n",
    "    def extract_all_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Extract both NYTimes and Goodreads data for all categories\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Starting data extraction process for all categories...\")\n",
    "\n",
    "            all_books_data = []\n",
    "\n",
    "            # Step 1: Extract NYTimes data for each category\n",
    "            for category in self.categories:\n",
    "                self.logger.info(f\"\\nProcessing category: {category}\")\n",
    "\n",
    "                # Extract NYT data for current category\n",
    "                nyt_df = self._extract_nyt_books(category)\n",
    "\n",
    "                if not nyt_df.empty:\n",
    "                    # Step 2: Extract Goodreads data for each book in the category\n",
    "                    for idx, row in nyt_df.iterrows():\n",
    "                        isbn = row['isbn13']\n",
    "                        self.logger.info(f\"Processing {idx + 1}/{len(nyt_df)}: {row['title']} (ISBN: {isbn})\")\n",
    "\n",
    "                        if pd.notnull(isbn):\n",
    "                            goodreads_info = self._extract_goodreads_data(str(isbn))\n",
    "                            # Combine NYT and Goodreads data for the book\n",
    "                            book_data = {**row.to_dict(), **goodreads_info}\n",
    "                            all_books_data.append(book_data)\n",
    "                        else:\n",
    "                            # If no ISBN, still keep the NYT data but with null Goodreads info\n",
    "                            book_data = {**row.to_dict(),\n",
    "                                       'goodreads_rating': None,\n",
    "                                       'goodreads_rating_count': None,\n",
    "                                       'goodreads_url': None}\n",
    "                            all_books_data.append(book_data)\n",
    "\n",
    "            # Create final DataFrame\n",
    "            combined_df = pd.DataFrame(all_books_data)\n",
    "\n",
    "            # Save raw data\n",
    "            extraction_date = datetime.now().strftime('%Y%m%d')\n",
    "            filename = f'raw_books_data_{extraction_date}.csv'\n",
    "            combined_df.to_csv(filename, index=False)\n",
    "            self.logger.info(f\"Data saved to {filename}\")\n",
    "\n",
    "            # Print summary statistics\n",
    "            self.logger.info(\"\\nExtraction Summary:\")\n",
    "            for category in self.categories:\n",
    "                category_books = combined_df[combined_df['category'] == category]\n",
    "                self.logger.info(f\"\\n{category}:\")\n",
    "                self.logger.info(f\"Total books: {len(category_books)}\")\n",
    "                self.logger.info(f\"Books with Goodreads ratings: {category_books['goodreads_rating'].notna().sum()}\")\n",
    "\n",
    "            return combined_df\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in extraction process: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oDL-YDERIYj",
    "outputId": "f4dba865-a1dd-4126-9cbf-23bed17849db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 13:09:54,503 - INFO - Starting data extraction process for all categories...\n",
      "2024-11-19 13:09:54,504 - INFO - \n",
      "Processing category: childrens-middle-grade-hardcover\n",
      "2024-11-19 13:09:54,505 - INFO - Starting NYTimes extraction for childrens-middle-grade-hardcover list\n",
      "2024-11-19 13:09:55,967 - INFO - Successfully extracted 10 books from NYTimes category: childrens-middle-grade-hardcover\n",
      "2024-11-19 13:09:55,969 - INFO - Processing 1/10: IMPOSSIBLE CREATURES (ISBN: 9780593809860)\n",
      "2024-11-19 13:10:05,000 - INFO - Processing 2/10: THE MILLICENT QUIBB SCHOOL OF ETIQUETTE FOR YOUNG LADIES OF MAD SCIENCE (ISBN: 9780316554732)\n",
      "2024-11-19 13:10:14,242 - INFO - Processing 3/10: THE LAST DRAGON ON MARS (ISBN: 9781665946513)\n",
      "2024-11-19 13:10:23,765 - INFO - Processing 4/10: THE BLETCHLEY RIDDLE (ISBN: 9780593527542)\n",
      "2024-11-19 13:10:31,872 - INFO - Processing 5/10: THE COMPLETE COOKBOOK FOR YOUNG CHEFS (ISBN: 9781492670025)\n",
      "2024-11-19 13:10:42,900 - INFO - Processing 6/10: THE COMPLETE BAKING BOOK FOR YOUNG CHEFS (ISBN: 9781492677697)\n",
      "2024-11-19 13:10:55,221 - INFO - Processing 7/10: WONDER (ISBN: 9780375869020)\n",
      "2024-11-19 13:11:09,849 - INFO - Processing 8/10: HEROES (ISBN: 9781338736076)\n",
      "2024-11-19 13:11:18,884 - INFO - Processing 9/10: PRICELESS FACTS ABOUT MONEY (ISBN: 9781536224719)\n",
      "2024-11-19 13:11:24,982 - INFO - Processing 10/10: MOUSE AND HIS DOG (ISBN: 9781250345004)\n",
      "2024-11-19 13:11:32,486 - INFO - \n",
      "Processing category: picture-books\n",
      "2024-11-19 13:11:32,487 - INFO - Starting NYTimes extraction for picture-books list\n",
      "2024-11-19 13:11:33,812 - INFO - Successfully extracted 10 books from NYTimes category: picture-books\n",
      "2024-11-19 13:11:33,813 - INFO - Processing 1/10: CHRISTMAS AT HOGWARTS (ISBN: 9781546129950)\n",
      "2024-11-19 13:11:44,150 - INFO - Processing 2/10: HOW TO CATCH A TURKEY (ISBN: 9781492664352)\n",
      "2024-11-19 13:12:00,881 - INFO - Processing 3/10: TAYLOR SWIFT (ISBN: 9780593566718)\n",
      "2024-11-19 13:12:13,420 - INFO - Processing 4/10: MS. RACHEL AND THE SPECIAL SURPRISE (ISBN: 9780593811252)\n",
      "2024-11-19 13:12:20,751 - INFO - Processing 5/10: CHICKA CHICKA HO HO HO (ISBN: 9781665954761)\n",
      "2024-11-19 13:12:29,845 - INFO - Processing 6/10: DON'T LET THE PIGEON DRIVE THE SLEIGH! (ISBN: 9781454952770)\n",
      "2024-11-19 13:12:37,025 - INFO - Processing 7/10: BLUEY: BARTLEBEE'S FIRST CHRISTMAS (ISBN: 9780593755068)\n",
      "2024-11-19 13:12:47,556 - INFO - Processing 8/10: GRUMPY MONKEY OH, NO! CHRISTMAS (ISBN: 9780593306093)\n",
      "2024-11-19 13:13:01,449 - INFO - Processing 9/10: HOW TO CATCH SANTA CLAUS (ISBN: 9781728274270)\n",
      "2024-11-19 13:13:08,737 - INFO - Processing 10/10: THE SNOW THIEF (ISBN: 9781464226786)\n",
      "2024-11-19 13:13:17,291 - INFO - \n",
      "Processing category: series-books\n",
      "2024-11-19 13:13:17,292 - INFO - Starting NYTimes extraction for series-books list\n",
      "2024-11-19 13:13:18,890 - INFO - Successfully extracted 10 books from NYTimes category: series-books\n",
      "2024-11-19 13:13:18,892 - INFO - Processing 1/10: DIARY OF A WIMPY KID (ISBN: 9781419766954)\n",
      "2024-11-19 13:13:26,163 - INFO - Processing 2/10: THE WILD ROBOT (ISBN: 9780316382007)\n",
      "2024-11-19 13:13:34,269 - INFO - Processing 3/10: PERCY JACKSON & THE OLYMPIANS (ISBN: 9781368107631)\n",
      "2024-11-19 13:13:42,393 - INFO - Processing 4/10: HARRY POTTER (ISBN: 9781338878929)\n",
      "2024-11-19 13:13:51,625 - INFO - Processing 5/10: SHATTER ME (ISBN: 9780063419407)\n",
      "2024-11-19 13:13:59,579 - INFO - Processing 6/10: THE POWERLESS TRILOGY (ISBN: 9781665954884)\n",
      "2024-11-19 13:14:08,091 - INFO - Processing 7/10: CARAVAL (ISBN: 9781250095268)\n",
      "2024-11-19 13:14:19,110 - INFO - Processing 8/10: WHO WAS/IS . . . ? (ISBN: 9780593754221)\n",
      "2024-11-19 13:14:33,524 - INFO - Processing 9/10: THE HUNGER GAMES (ISBN: 9780439023528)\n",
      "2024-11-19 13:15:22,561 - INFO - Processing 10/10: A GOOD GIRL'S GUIDE TO MURDER (ISBN: 9781984896391)\n",
      "2024-11-19 13:15:40,302 - INFO - \n",
      "Processing category: young-adult-hardcover\n",
      "2024-11-19 13:15:40,303 - INFO - Starting NYTimes extraction for young-adult-hardcover list\n",
      "2024-11-19 13:15:42,756 - INFO - Successfully extracted 10 books from NYTimes category: young-adult-hardcover\n",
      "2024-11-19 13:15:42,758 - INFO - Processing 1/10: A STUDY IN DROWNING (ISBN: 9780063419414)\n",
      "2024-11-19 13:15:51,214 - INFO - Processing 2/10: WHERE THE LIBRARY HIDES (ISBN: 9781250377166)\n",
      "2024-11-19 13:15:58,961 - INFO - Processing 3/10: IF HE HAD BEEN WITH ME (ISBN: 9781464231025)\n",
      "2024-11-19 13:16:07,919 - INFO - Processing 4/10: NOTHING LIKE THE MOVIES (ISBN: 9781665947138)\n",
      "2024-11-19 13:16:20,385 - INFO - Processing 5/10: LIGHTLARK (ISBN: 9781419760860)\n",
      "2024-11-19 13:16:30,385 - INFO - Processing 6/10: MURTAGH (ISBN: 9780593898000)\n",
      "2024-11-19 13:16:39,611 - INFO - Processing 7/10: THE GLASS GIRL (ISBN: 9780525708087)\n",
      "2024-11-19 13:16:47,907 - INFO - Processing 8/10: STRANGER SKIES (ISBN: 9781665970853)\n",
      "2024-11-19 13:16:50,546 - INFO - Processing 9/10: DON'T LET THE FOREST IN (ISBN: 9781250388353)\n",
      "2024-11-19 13:16:52,742 - INFO - Processing 10/10: IMMORTAL DARK (ISBN: 9780316570381)\n",
      "2024-11-19 13:17:00,260 - INFO - Data saved to raw_books_data_20241119.csv\n",
      "2024-11-19 13:17:00,261 - INFO - \n",
      "Extraction Summary:\n",
      "2024-11-19 13:17:00,265 - INFO - \n",
      "childrens-middle-grade-hardcover:\n",
      "2024-11-19 13:17:00,266 - INFO - Total books: 10\n",
      "2024-11-19 13:17:00,267 - INFO - Books with Goodreads ratings: 10\n",
      "2024-11-19 13:17:00,268 - INFO - \n",
      "picture-books:\n",
      "2024-11-19 13:17:00,268 - INFO - Total books: 10\n",
      "2024-11-19 13:17:00,269 - INFO - Books with Goodreads ratings: 10\n",
      "2024-11-19 13:17:00,270 - INFO - \n",
      "series-books:\n",
      "2024-11-19 13:17:00,270 - INFO - Total books: 10\n",
      "2024-11-19 13:17:00,270 - INFO - Books with Goodreads ratings: 10\n",
      "2024-11-19 13:17:00,271 - INFO - \n",
      "young-adult-hardcover:\n",
      "2024-11-19 13:17:00,276 - INFO - Total books: 10\n",
      "2024-11-19 13:17:00,277 - INFO - Books with Goodreads ratings: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of Extracted Data:\n",
      "                                               title  \\\n",
      "0                               IMPOSSIBLE CREATURES   \n",
      "1  THE MILLICENT QUIBB SCHOOL OF ETIQUETTE FOR YO...   \n",
      "2                            THE LAST DRAGON ON MARS   \n",
      "3                               THE BLETCHLEY RIDDLE   \n",
      "4              THE COMPLETE COOKBOOK FOR YOUNG CHEFS   \n",
      "\n",
      "                            author         isbn13                publisher  \\\n",
      "0               Katherine Rundell.  9780593809860                    Knopf   \n",
      "1                    Kate McKinnon  9780316554732            Little, Brown   \n",
      "2                   Scott Reintgen  9781665946513                  Aladdin   \n",
      "3  Ruta Sepetys and Steve Sheinkin  9780593527542                   Viking   \n",
      "4      America's Test Kitchen Kids  9781492670025  Sourcebooks Jabberwocky   \n",
      "\n",
      "                                         description  \\\n",
      "0  A young boy is enlisted to save a place where ...   \n",
      "1  Three sisters attend an unusual etiquette scho...   \n",
      "2  Lunar must save the planet of Mars with a drag...   \n",
      "3  The siblings Jakob and Lizzie decode wartime s...   \n",
      "4  Over 100 kid-tested recipes from America's Tes...   \n",
      "\n",
      "                                  amazon_product_url  nyt_rank  \\\n",
      "0  https://www.amazon.com/dp/0593809866?tag=thene...         1   \n",
      "1  https://www.amazon.com/dp/0316554731?tag=thene...         2   \n",
      "2  https://www.amazon.com/dp/1665946512?tag=thene...         3   \n",
      "3  https://www.amazon.com/dp/0593527542?tag=thene...         4   \n",
      "4  https://www.amazon.com/Complete-Cookbook-Young...         5   \n",
      "\n",
      "   nyt_rank_last_week  weeks_on_list price primary_isbn10  \\\n",
      "0                   1              9  0.00     0593809866   \n",
      "1                   3              6  0.00     0316554731   \n",
      "2                   6              6  0.00     1665946512   \n",
      "3                   4              5  0.00     0593527542   \n",
      "4                   5            223  0.00     1492670022   \n",
      "\n",
      "                           category extraction_date  goodreads_rating  \\\n",
      "0  childrens-middle-grade-hardcover      2024-11-19              4.17   \n",
      "1  childrens-middle-grade-hardcover      2024-11-19              4.10   \n",
      "2  childrens-middle-grade-hardcover      2024-11-19              4.28   \n",
      "3  childrens-middle-grade-hardcover      2024-11-19              4.21   \n",
      "4  childrens-middle-grade-hardcover      2024-11-19              4.40   \n",
      "\n",
      "   goodreads_rating_count                                      goodreads_url  \n",
      "0                  8727.0  https://www.goodreads.com/book/isbn/9780593809860  \n",
      "1                   632.0  https://www.goodreads.com/book/isbn/9780316554732  \n",
      "2                   261.0  https://www.goodreads.com/book/isbn/9781665946513  \n",
      "3                  1868.0  https://www.goodreads.com/book/isbn/9780593527542  \n",
      "4                   815.0  https://www.goodreads.com/book/isbn/9781492670025  \n",
      "\n",
      "Data Summary by Category:\n",
      "                                  Total Books  Books with Ratings\n",
      "category                                                         \n",
      "childrens-middle-grade-hardcover           10                  10\n",
      "picture-books                              10                  10\n",
      "series-books                               10                  10\n",
      "young-adult-hardcover                      10                   8\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # NYTimes API key\n",
    "    NYT_API_KEY = \"sn8Mfl8hlG9hf2dNiFteGH3RqREbaz5L\"\n",
    "\n",
    "    # Initialize extractor\n",
    "    extractor = BooksDataExtractor(NYT_API_KEY)\n",
    "\n",
    "    try:\n",
    "        # Extract data\n",
    "        df = extractor.extract_all_data()\n",
    "\n",
    "        # Display sample of extracted data\n",
    "        print(\"\\nSample of Extracted Data:\")\n",
    "        print(df.head())\n",
    "\n",
    "        # Display summary by category\n",
    "        print(\"\\nData Summary by Category:\")\n",
    "        print(df.groupby('category').agg({\n",
    "            'title': 'count',\n",
    "            'goodreads_rating': lambda x: x.notna().sum()\n",
    "        }).rename(columns={\n",
    "            'title': 'Total Books',\n",
    "            'goodreads_rating': 'Books with Ratings'\n",
    "        }))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main process: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jl_I316kImo"
   },
   "source": [
    "# **TRANSFORM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "q8lWWeg3X4vO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def transform_relevant_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Select and clean relevant columns for BI analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Remove rows with empty ratings\n",
    "    filtered_df = df[df['goodreads_rating'].notnull() & (df['goodreads_rating'] != \"\")].copy()\n",
    "\n",
    "    # Step 2: Convert 'goodreads_rating' to numeric (if not already done in extract stage)\n",
    "    filtered_df['goodreads_rating'] = pd.to_numeric(filtered_df['goodreads_rating'], errors='coerce')\n",
    "\n",
    "    # Define relevant columns\n",
    "    relevant_columns = [\n",
    "        'title', 'author', 'isbn13', 'nyt_rank', 'nyt_rank_last_week',\n",
    "        'weeks_on_list', 'category', 'extraction_date',\n",
    "        'goodreads_rating', 'goodreads_rating_count'\n",
    "    ]\n",
    "\n",
    "    # Select only the relevant columns\n",
    "    transformed_df = filtered_df[relevant_columns].copy()\n",
    "\n",
    "    # Step 3: Standardize 'category' column formatting\n",
    "    transformed_df['category'] = transformed_df['category'].str.strip().str.title()\n",
    "\n",
    "    # Step 4: Handle missing values in counts\n",
    "    transformed_df['goodreads_rating_count'] = transformed_df['goodreads_rating_count'].fillna(0)\n",
    "\n",
    "    # Step 5: Convert numeric columns to the correct type\n",
    "    numeric_columns = ['nyt_rank', 'nyt_rank_last_week', 'weeks_on_list', 'goodreads_rating', 'goodreads_rating_count']\n",
    "    for col in numeric_columns:\n",
    "        transformed_df[col] = pd.to_numeric(transformed_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Step 6: Ensure 'extraction_date' is a datetime format\n",
    "    transformed_df['extraction_date'] = pd.to_datetime(transformed_df['extraction_date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    return transformed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MYZEMZhLkOzo"
   },
   "outputs": [],
   "source": [
    "def transform_data_pipeline(raw_file_path: str, transformed_file_path: str):\n",
    "    \"\"\"\n",
    "    Transform raw data file for BI purposes and save the result.\n",
    "\n",
    "    Args:\n",
    "        raw_file_path (str): Path to the raw data CSV file.\n",
    "        transformed_file_path (str): Path to save the transformed data CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load raw data\n",
    "        print(f\"Loading raw data from {raw_file_path}...\")\n",
    "        raw_df = pd.read_csv(raw_file_path)\n",
    "\n",
    "        # Transform data\n",
    "        print(\"Transforming data...\")\n",
    "        transformed_df = transform_relevant_columns(raw_df)\n",
    "\n",
    "        # Save transformed data\n",
    "        print(f\"Saving transformed data to {transformed_file_path}...\")\n",
    "        transformed_df.to_csv(transformed_file_path, index=False)\n",
    "\n",
    "        # Display summary\n",
    "        print(\"\\nTransformation Summary:\")\n",
    "        summary = transformed_df.groupby('category').agg({\n",
    "            'title': 'count',\n",
    "            'goodreads_rating': lambda x: (x > 0).sum()\n",
    "        }).rename(columns={\n",
    "            'title': 'Total Books',\n",
    "            'goodreads_rating': 'Books with Ratings'\n",
    "        })\n",
    "        print(summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during transformation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNd5nRY1kR4I",
    "outputId": "58c891c4-71f6-4f5b-abea-b9f8fa322d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data from raw_books_data_20241119.csv...\n",
      "Transforming data...\n",
      "Saving transformed data to transformed_books_data_20241119.csv...\n",
      "\n",
      "Transformation Summary:\n",
      "                                  Total Books  Books with Ratings\n",
      "category                                                         \n",
      "Childrens-Middle-Grade-Hardcover           10                  10\n",
      "Picture-Books                              10                  10\n",
      "Series-Books                               10                  10\n",
      "Young-Adult-Hardcover                       8                   8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths for raw and transformed data\n",
    "    extraction_date = datetime.now().strftime('%Y%m%d')\n",
    "    raw_file = f'raw_books_data_{extraction_date}.csv'\n",
    "    transformed_file = f'transformed_books_data_{extraction_date}.csv'\n",
    "\n",
    "    # Run transformation pipeline\n",
    "    transform_data_pipeline(raw_file, transformed_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0wGpJAFnjuS"
   },
   "source": [
    "# **LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0s7bYS90sEts",
    "outputId": "d4058b38-ecbc-4e3b-8ca4-235715d6ed04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongoNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pymongo-4.10.1-cp313-cp313-win_amd64.whl.metadata (22 kB)\n",
      "Collecting dnspython\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading pymongo-4.10.1-cp313-cp313-win_amd64.whl (976 kB)\n",
      "   ---------------------------------------- 0.0/976.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 976.9/976.9 kB 8.4 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.10.1\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo dnspython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_4BaIgHfnlcu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Y1m8bMPinvO_"
   },
   "outputs": [],
   "source": [
    "def load_data_to_mongodb(transformed_df: pd.DataFrame, connection_string: str, db_name: str, collection_name: str):\n",
    "    \"\"\"\n",
    "    Load the transformed data into MongoDB Atlas.\n",
    "\n",
    "    Args:\n",
    "        transformed_df (pd.DataFrame): The transformed data to load.\n",
    "        connection_string (str): MongoDB Atlas connection string.\n",
    "        db_name (str): The database name in MongoDB.\n",
    "        collection_name (str): The collection name in MongoDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB Atlas\n",
    "        print(\"Connecting to MongoDB Atlas...\")\n",
    "        client = MongoClient(connection_string)\n",
    "        db = client[db_name]\n",
    "        collection = db[collection_name]\n",
    "\n",
    "        # Convert the DataFrame to a dictionary (list of dicts)\n",
    "        records = transformed_df.to_dict(orient='records')\n",
    "\n",
    "        # Insert data into MongoDB collection\n",
    "        print(f\"Loading data into collection '{collection_name}'...\")\n",
    "        collection.insert_many(records)\n",
    "\n",
    "        print(\"Data loaded successfully into MongoDB!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading data to MongoDB: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tq18dX2jnxob",
    "outputId": "be9128d5-bef3-437c-a376-cb8cb7974dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MongoDB Atlas...\n",
      "Loading data into collection 'books'...\n",
      "Data loaded successfully into MongoDB!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set paths for raw and transformed data (assuming already transformed to DataFrame)\n",
    "    extraction_date = datetime.now().strftime('%Y%m%d')\n",
    "    raw_file = f'transformed_books_data_20241119.csv'\n",
    "\n",
    "    # Load and transform data (using previously defined function)\n",
    "    transformed_df = pd.read_csv(raw_file)  # Assuming the dataframe is already transformed\n",
    "\n",
    "    # MongoDB connection string (replace with your actual credentials)\n",
    "    connection_string = \"mongodb+srv://bulanmurela:Bulanmurela1144@rekdat.hn7zp.mongodb.net/\"\n",
    "\n",
    "    # MongoDB database and collection names\n",
    "    db_name = \"etl_pipeline_db\"\n",
    "    collection_name = \"books\"\n",
    "\n",
    "    # Load transformed data to MongoDB\n",
    "    load_data_to_mongodb(transformed_df, connection_string, db_name, collection_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
